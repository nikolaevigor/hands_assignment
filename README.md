# Тестовое задание

## Текст задания

Компания делает сайт: стандартный справочник организаций. Клиенты на сайте ищут номера телефонов организаций. Номера телефонов устаревают. Из-за этого компания теряет клиентов.

Для каждой организации в базе хранится ссылка на её сайт и путь к странице контактов. Страниц контактов на одном сайте может быть несколько. Есть модуль, который умеет распознавать неактуальный номер. На вход он получает список номеров в формате 8KKKNNNNNNN.

Вам нужно написать модуль, который скачивает web-страницы, находит в тексте и выводит все распознанные номера телефонов в этом формате.

Номера по формату российские. Если для номера не указан код города — номер московский.

Чем выше доля распознаваемых реальных номеров на странице и чем быстрее работает модуль — тем он лучше. Здесь: https://hands.ru/company/about модуль должен найти номер, здесь: https://repetitors.info тоже. Страниц в базе может быть очень много!

В задании не нужно использовать тяжелые фреймворки, или сохранять найденные номера в базу. Задание ориентировано буквально на несколько часов.

Решение нужно предоставить в виде отдельного репозитория на github.com

## Комментарии соискателя

Данная задача классифицируется как IO bound. Соответственно для эффективного использования процессорного времени я использовал трединг.

Для каждого урла создаем отдельный поток, который сделает запрос (с некоторым таймаутом) и полученный ответ положит в очередь. В основном потоке будем пулить из очереди и обрабатывать все ответы, так как обработку можно назвать CPU bound задачей.

В основном потоке прогоняем полученный html страницы через регулярку, форматируем и получаем телефоны вида 8KKKNNNNNNN. Выбрал эту регулярку так как на мой взгляд она оптимальна между "не мэтчится то, что надо" и "мэтчится то, что не надо (например различные id)".

Из сторонних библиотек исользована только requests.

Альтернативным подходом может являться использование asyncio. Но так как requests написана в синхронном стиле, а aiohttp тащить не хотелось, я его не использовал.

### Допущения

- урлы уже загружены в память (на этом месте могли бы быть коннекторы к базе, либо к брокеру сообщений или любому другому IPC)

- так как это тестовое задание, я завершаю процесс, если в очереди секунду ничего не было


## Ответ работодателя


Что понравилось:
- классное решение через queue.

Вопросы и замечания:
- Насколько эффективен .replace(...).replace(...)
- почему print, a не logging?
- _process_pages ничего не возвращает, как использовать этот модуль в production?
- что будет, если requests ответит не 200?

## Комментарий

К сожалению после ответа, вакансия на hh ушла в архив и у меня не было возможности ответить, поэтому отвечу здесь.

1) 5 реплейсов это O(5n), то есть асимптотически также эффективно как один проход.

2) print потому что в данном случае он используется исключительно для иллюстрации работы программы. В рамках тестового задания развернутый сетап логера из модуля logging занял бы приблизительно 30% строк в файле.

3) _process_pages это метод созданный для красоты кода, чтобы в try except ниже не иметь огромный блок с большим отступом.
Так или иначе в контексте поставленной задачи этот метод не должен ничего возвращать. В этом методе вызывается бесконечный луп обработки сообщений из очереди. Что делать с обработанными сообщениями (отправлять ли их в RabbitMQ, писать ли в БД, класть ли в Redis) указано не было. Поэтому я оставил в том месте комментарий.

4) Здесь согласен, не предусмотрел
